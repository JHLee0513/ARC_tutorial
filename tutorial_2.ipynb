{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to ConvNets (CNN) in keras\n",
    "\n",
    "Now that you have some idea of how to use keras, we will use that to build a convolutional neural network! It is the main type of network that we will utilize to program our self-driving cars.\n",
    "\n",
    "\n",
    "# The problem/dataset\n",
    "\n",
    "As our toy problem, we will look into CIFAR10, this is one of a good, publicly open dataset that can be used to test your model for general object classification performance. In this dataset contains 60K images in 32x32 resolution. Not only does this have a good amount of data for proper learning to take place, it has multiple classes to practice multi-class classification task.\n",
    "\n",
    "Citation: Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We will first load our dataset. The process is as follows:\n",
    "\n",
    "## Mac/Linux-based OS\n",
    "1. Download the python version for CIFAR-10 from [here](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "2. Uncompress the .tar.gz file\n",
    "\n",
    "## Windows\n",
    "1. Download the python version for CIFAR-10 from [here](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_data(address):\n",
    "    data = []\n",
    "    for path in glob(address + \"/*\"):\n",
    "        tmp = unpickle(path)\n",
    "        data.append(tmp)\n",
    "    if (len(data)==0):\n",
    "        print(\"Oh no! data is None, which means it failed to load.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(\"/Users/Hal/ARC_tutorial/CIFAR_10/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,  43,  50, ..., 140,  84,  72],\n",
       "       [154, 126, 105, ..., 139, 142, 144],\n",
       "       [255, 253, 253, ...,  83,  83,  84],\n",
       "       ...,\n",
       "       [ 71,  60,  74, ...,  68,  69,  68],\n",
       "       [250, 254, 211, ..., 215, 255, 254],\n",
       "       [ 62,  61,  60, ..., 130, 130, 131]], dtype=uint8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(temp[b'data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xy(input_list, x, y):\n",
    "    for i in range(len(input_list)):\n",
    "        batch = input_list[i]\n",
    "        labels = batch[b'labels']\n",
    "        data = np.array(batch[b'data']) #3072 length vector\n",
    "        data = np.reshape(data, (10000,32,32,3))\n",
    "        x[i*len(labels):(i+1)*len(labels),:,:,:] = data\n",
    "        y[i*len(labels):(i+1)*len(labels)] = labels\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = extract_xy(train_data,np.empty((50000,32,32,3)), np.empty(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,)\n"
     ]
    }
   ],
   "source": [
    "#Here we can check our data shapes to confirm the data has been processed\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "What's good at starting numbers and matrices? Hence we look at some ways to visualize our data before modelling. This is known as part of a process called Explanatory Data Analysis (EDA) where the engineer can look at the data for better understanding of it overall, before diving into crunching numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at example Images\n",
    "\n",
    "In the case of Computer Vision, it is helpful for us to actually look at some of the images and some general information about the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y(output class) distribution\n",
    "\n",
    "We can also look at the labels to get some ideas about our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_layer = layers.Input(shape=(32,32,3))\n",
    "    conv1 = Conv2D(32, (3,3), strides=1, activation='relu') (input_layer)\n",
    "    pool1 = MaxPooling2D((2,2))(conv1)\n",
    "    conv2 = Conv2D(64, (3,3), strides=1, activation='relu') (pool1)\n",
    "    pool2 = MaxPooling2D((2,2))(conv2)\n",
    "    conv3 = Conv2D(128, (3,3), strides=1, activation='relu') (pool2)\n",
    "    pool3 = MaxPooling2D((2,2))(conv3)\n",
    "    conv4 = Conv2D(256, (3,3), strides=1, activation='relu') (pool3)\n",
    "    glob = GlobalMaxPooling2D() (conv4)\n",
    "    fc1 = Dense(512) (glob)\n",
    "    fc2 = Dense(1024) (fc2)\n",
    "    fc3 = Dense(10, activation = 'softmax') (fc3)\n",
    "    \n",
    "    return Model(input_layer, fc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (from keras.applications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_xception():\n",
    "    model = applications.xception()\n",
    "    model.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile, train, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval():\n",
    "\n",
    "model = build_model()\n",
    "model.compile()\n",
    "model.fit()\n",
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now used various CNN models for the image classification task with Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
